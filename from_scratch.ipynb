{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the doc:\n",
    "\n",
    "http://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.FloatTensor(2, 3)\n",
    "print(a)\n",
    "print(a.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### are Numpy arrays inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = a.numpy()\n",
    "a_[0, 0] = 0.\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.ones(2, 2))\n",
    "print(x)\n",
    "print(x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### are Tensors inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with automatic differentiation !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad=True\n",
    "\n",
    "y = x + 2\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y * y * 3\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)\n",
    "\n",
    "error = (10 - z).mean()\n",
    "error.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descente de gradient: exemple\n",
    "\n",
    "On calcule les gradients $\\frac{\\partial L(y - h(x))}{\\partial w}$ et $\\frac{\\partial L(y - h(x))}{\\partial b}$, avec:\n",
    " - $h(x) = \\sigma(w*x + b)$\n",
    " - $\\sigma$ est la fonction logistique (sigmoid)\n",
    " - $L(y, \\hat{y}) = (y - \\hat{y})^2$ (erreur quadratique)\n",
    " - $y = 0.2$\n",
    " - $x = 1.5$\n",
    " - $b = -2$\n",
    " - $w = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor([1.5]))\n",
    "y = Variable(torch.Tensor([0.2]))\n",
    "b = Variable(torch.Tensor([-2.0]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([3.0]), requires_grad=True)\n",
    "h = torch.sigmoid(w * x + b)\n",
    "error = (y - h)**2\n",
    "error.backward()\n",
    "\n",
    "print(h.data[0])\n",
    "print(w.grad.data[0])\n",
    "print(b.grad.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On minimize $L(y - h(x))$ pas à pas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor([1.5]))\n",
    "y = Variable(torch.Tensor([0.2]))\n",
    "b = Variable(torch.Tensor([-2.0]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([3.0]), requires_grad=True)\n",
    "\n",
    "alpha = 1\n",
    "for i in range(100):\n",
    "    h = torch.sigmoid(w * x + b)\n",
    "    error = (y - h)**2\n",
    "    error.backward()\n",
    "    \n",
    "    w.data.sub_(alpha * w.grad.data)\n",
    "    w.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    b.data.sub_(alpha * b.grad.data)\n",
    "    b.grad.data.zero_()  # must reset to 0 before next pass\n",
    "    \n",
    "    print('Epoch {} h={:.05f} w={:.05f} b={:.05f}'.format(i+1, h.data[0], w.data[0], b.data[0]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayez différentes valeurs pour le paramètre alpha: 0.01, 0.1, 1, 10, 100. Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A vous de jouer !\n",
    "\n",
    "Voici un jeu de données synthetique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "X_ = np.concatenate((\n",
    "    np.random.random(\n",
    "        size=(5000, 2)) - 0.5,\n",
    "    np.random.multivariate_normal(\n",
    "        size=(2500, ),\n",
    "        mean=(-.25, -.25),\n",
    "        cov=((0.005, 0), (0, 0.005))),\n",
    "    np.random.multivariate_normal(\n",
    "        size=(2500, ),\n",
    "        mean=(0.25, 0.25),\n",
    "        cov=((0.005, 0), (0, 0.005))),\n",
    "))\n",
    "\n",
    "Y_ = np.concatenate((\n",
    "    np.zeros(shape=(5000, 1)),\n",
    "    np.ones(shape=(5000, 1)),\n",
    "))\n",
    "\n",
    "X_ = np.asarray(X_, dtype='float32')\n",
    "Y_ = np.asarray(Y_, dtype='float32')\n",
    "\n",
    "# shuffle data points\n",
    "perm = np.random.permutation(X_.shape[0])\n",
    "X_ = X_[perm]\n",
    "Y_ = Y_[perm]\n",
    "\n",
    "# numpy arrays -> torch tensors\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "X = torch.from_numpy(X_)\n",
    "Y = torch.from_numpy(Y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée deux jeux séparés: train / test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# train / test split\n",
    "n_train = 100\n",
    "n_test = 100\n",
    "\n",
    "X_train = X[:n_train]\n",
    "Y_train = Y[:n_train]\n",
    "\n",
    "X_test = X[n_train:(n_train + n_test)]\n",
    "Y_test = Y[n_train:(n_train + n_test)]\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8), squeeze=False)\n",
    "axes[0, 0].set_title('train')\n",
    "axes[0, 0].scatter(\n",
    "    X_train[:, 0].numpy(),\n",
    "    X_train[:, 1].numpy(),\n",
    "    c=Y_train[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "axes[0, 1].set_title('test')\n",
    "axes[0, 1].scatter(\n",
    "    X_test[:, 0].numpy(),\n",
    "    X_test[:, 1].numpy(),\n",
    "    c=Y_test[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentez un réseau de neurones sans couche cachée, qui prends en entrée $\\mathbf{x} \\in \\mathbb{R}^2$ et produit une seule sortie $\\mathbf{y} \\in [0, 1]$ (sigmoid).\n",
    "\n",
    "Multiplication de matrics: torch.matmul\n",
    "\n",
    "Interdiction d'utiliser les modules haut niveau de pytorch ! (optim, nn etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_in = 2\n",
    "params = []\n",
    "\n",
    "n_out = 1\n",
    "W = Variable(torch.normal(torch.zeros(n_in, n_out), np.sqrt(2/(n_in + n_out))), requires_grad=True)\n",
    "b = Variable(torch.zeros(n_out), requires_grad=True)\n",
    "\n",
    "def forward(X):\n",
    "    H = ...\n",
    "    \n",
    "    return H\n",
    "\n",
    "\n",
    "def L(H, Y, eps=1e-08):\n",
    "    loss = -Y * torch.log(H + eps) - (1 - Y) * torch.log(1 - H + eps)  # log-likelikood\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "n_epochs = 250\n",
    "epoch_n_batches = 100\n",
    "train_batch_size = 10\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(n_epochs):\n",
    "\n",
    "    train_loss = 0.\n",
    "\n",
    "    for j in range(epoch_n_batches):\n",
    "\n",
    "        # Prepare next mini-batch\n",
    "        mb_idxs = torch.multinomial(torch.ones(n_train), train_batch_size, replacement=True)\n",
    "        X_mb = Variable(X_train[mb_idxs])\n",
    "        Y_mb = Variable(Y_train[mb_idxs])\n",
    "\n",
    "        # Forward pass\n",
    "        Y_prob_mb = forward(X_mb)\n",
    "        \n",
    "        loss = ...\n",
    "\n",
    "        # Backward pass\n",
    "        # TODO\n",
    "\n",
    "        # Parameter update (gradient descent)\n",
    "        # TODO\n",
    "\n",
    "        train_loss += loss.data[0]\n",
    "\n",
    "    train_loss /= epoch_n_batches\n",
    "\n",
    "    # Forward pass\n",
    "    Y_test_prob = forward(Variable(X_test)).data\n",
    "    test_loss = L(Y_test_prob, Y_test).mean()\n",
    "    \n",
    "    # Compute expected 0/1 error\n",
    "    Y_test_pred = (Y_test_prob > 0.5).type(torch.FloatTensor)\n",
    "    test_err = torch.abs(Y_test - Y_test_pred).mean()\n",
    "\n",
    "    print('Epoch {:03d}\\ttrain loss={:.06f}\\ttest loss={:.06f}\\t0/1 error={:.03f}'.format(\n",
    "        i + 1, train_loss, test_loss, test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisez la distribution apprise par votre modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_size = (100, 100)\n",
    "x1, x2 = np.meshgrid(np.linspace(X_[:, 0].min()-0.1, X_[:, 0].max()+0.1, map_size[0]),\n",
    "                     np.linspace(X_[:, 1].min()-0.1, X_[:, 1].max()+0.1, map_size[1]))\n",
    "X_map = torch.from_numpy(np.asarray(np.c_[x1.ravel(), x2.ravel()], dtype='float32'))\n",
    "\n",
    "Y_prob_map = forward(Variable(X_map)).data\n",
    "\n",
    "Y_train_pred = (forward(Variable(X_train)).data > 0.5).type(torch.FloatTensor)\n",
    "train_err = torch.abs(Y_train - Y_train_pred).mean()\n",
    "\n",
    "Y_test_pred = (forward(Variable(X_test)).data > 0.5).type(torch.FloatTensor)\n",
    "test_err = torch.abs(Y_test - Y_test_pred).mean()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8), squeeze=False)\n",
    "axes[0, 0].set_title('train accuracy={:.03f}'.format(1 - train_err))\n",
    "axes[0, 0].contourf(\n",
    "    x1,\n",
    "    x2,\n",
    "    Y_prob_map.numpy().reshape(map_size),\n",
    "    cmap=cm, vmin=0, vmax=1,\n",
    "    alpha=.8)\n",
    "axes[0, 0].scatter(\n",
    "    X_train[:, 0].numpy(),\n",
    "    X_train[:, 1].numpy(),\n",
    "    c=Y_train[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "axes[0, 1].set_title('test accuracy={:.03f}'.format(1 - test_err))\n",
    "axes[0, 1].contourf(\n",
    "    x1,\n",
    "    x2,\n",
    "    Y_prob_map.numpy().reshape(map_size),\n",
    "    cmap=cm, vmin=0, vmax=1,\n",
    "    alpha=.8)\n",
    "axes[0, 1].scatter(\n",
    "    X_test[:, 0].numpy(),\n",
    "    X_test[:, 1].numpy(),\n",
    "    c=Y_test[:, 0].numpy(),\n",
    "    cmap=cm_bright,\n",
    "    edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutez une couche cachée de taille 10 à votre réseau de neurones, avec la fonction d'activation relu (torch.clamp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: améliorez votre réseau de neurones: plus de neurones cachés, deuxième couche cachée etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
